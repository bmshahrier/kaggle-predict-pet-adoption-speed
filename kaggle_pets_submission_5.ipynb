{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the library\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "\n",
    "# sklearn :: utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# sklearn :: models\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "# from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# sklearn :: evaluation metrics\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict when a pet will be adopted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 24) (4993, 23)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('Data/train.csv')\n",
    "df_test = pd.read_csv('Data/test.csv')\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Type', 'Name', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
      "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
      "       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'RescuerID',\n",
      "       'VideoAmt', 'Description', 'PetID', 'PhotoAmt', 'AdoptionSpeed'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>...</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>RescuerID</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>Description</th>\n",
       "      <th>PetID</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>â¥â¥â¥ Lily â¥â¥â¥</td>\n",
       "      <td>36</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41326</td>\n",
       "      <td>337914b09c2fa5460e195197e994ef98</td>\n",
       "      <td>0</td>\n",
       "      <td>Adorable 3 year old Lily looking for a forever...</td>\n",
       "      <td>3f8824a3b</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>3</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41327</td>\n",
       "      <td>4bb1ebb92158078ad54a6bb23c10dffc</td>\n",
       "      <td>0</td>\n",
       "      <td>i rescue this stary kitten from market near my...</td>\n",
       "      <td>9238eb7fc</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Favour Speedy Abundance And Courage</td>\n",
       "      <td>7</td>\n",
       "      <td>250</td>\n",
       "      <td>252</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>41327</td>\n",
       "      <td>99ba8ce53b4d8515e417e7921563d923</td>\n",
       "      <td>0</td>\n",
       "      <td>The mother was a Burmese cross and had since p...</td>\n",
       "      <td>f0a1f2b90</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41327</td>\n",
       "      <td>3f3ef74c486beba3bc87f6dbaee772bf</td>\n",
       "      <td>0</td>\n",
       "      <td>This puppy is: 1. Male 2. 3 months old 3. Brow...</td>\n",
       "      <td>7d028bdea</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Abandoned Kitty</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41401</td>\n",
       "      <td>844f03ab8054007d4be6686f3a9702b9</td>\n",
       "      <td>0</td>\n",
       "      <td>Mother cat gave birth to a litter of 3 and too...</td>\n",
       "      <td>8377bfe97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type                                 Name  Age  Breed1  Breed2  Gender  \\\n",
       "0     1             â¥â¥â¥ Lily â¥â¥â¥   36     307       0       2   \n",
       "1     2                               Cookie    3     266       0       1   \n",
       "2     2  Favour Speedy Abundance And Courage    7     250     252       1   \n",
       "3     1                                  NaN    3     307       0       1   \n",
       "4     2                      Abandoned Kitty    1     266       0       1   \n",
       "\n",
       "   Color1  Color2  Color3  MaturitySize      ...        Health  Quantity  Fee  \\\n",
       "0       2       7       0             2      ...             1         1    0   \n",
       "1       6       7       0             2      ...             1         1    0   \n",
       "2       1       2       0             2      ...             1         4    0   \n",
       "3       2       0       0             3      ...             1         1    0   \n",
       "4       1       6       7             1      ...             1         1    0   \n",
       "\n",
       "   State                         RescuerID  VideoAmt  \\\n",
       "0  41326  337914b09c2fa5460e195197e994ef98         0   \n",
       "1  41327  4bb1ebb92158078ad54a6bb23c10dffc         0   \n",
       "2  41327  99ba8ce53b4d8515e417e7921563d923         0   \n",
       "3  41327  3f3ef74c486beba3bc87f6dbaee772bf         0   \n",
       "4  41401  844f03ab8054007d4be6686f3a9702b9         0   \n",
       "\n",
       "                                         Description      PetID PhotoAmt  \\\n",
       "0  Adorable 3 year old Lily looking for a forever...  3f8824a3b      1.0   \n",
       "1  i rescue this stary kitten from market near my...  9238eb7fc      1.0   \n",
       "2  The mother was a Burmese cross and had since p...  f0a1f2b90      2.0   \n",
       "3  This puppy is: 1. Male 2. 3 months old 3. Brow...  7d028bdea      4.0   \n",
       "4  Mother cat gave birth to a litter of 3 and too...  8377bfe97      0.0   \n",
       "\n",
       "   AdoptionSpeed  \n",
       "0              4  \n",
       "1              2  \n",
       "2              4  \n",
       "3              2  \n",
       "4              2  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_train.columns)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type               int64\n",
       "Name              object\n",
       "Age                int64\n",
       "Breed1             int64\n",
       "Breed2             int64\n",
       "Gender             int64\n",
       "Color1             int64\n",
       "Color2             int64\n",
       "Color3             int64\n",
       "MaturitySize       int64\n",
       "FurLength          int64\n",
       "Vaccinated         int64\n",
       "Dewormed           int64\n",
       "Sterilized         int64\n",
       "Health             int64\n",
       "Quantity           int64\n",
       "Fee                int64\n",
       "State              int64\n",
       "RescuerID         object\n",
       "VideoAmt           int64\n",
       "Description       object\n",
       "PetID             object\n",
       "PhotoAmt         float64\n",
       "AdoptionSpeed      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Type               0\n",
       "Name             842\n",
       "Age                0\n",
       "Breed1             0\n",
       "Breed2             0\n",
       "Gender             0\n",
       "Color1             0\n",
       "Color2             0\n",
       "Color3             0\n",
       "MaturitySize       0\n",
       "FurLength          0\n",
       "Vaccinated         0\n",
       "Dewormed           0\n",
       "Sterilized         0\n",
       "Health             0\n",
       "Quantity           0\n",
       "Fee                0\n",
       "State              0\n",
       "RescuerID          0\n",
       "VideoAmt           0\n",
       "Description        8\n",
       "PetID              0\n",
       "PhotoAmt           0\n",
       "AdoptionSpeed      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "df_train.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Breed1</th>\n",
       "      <th>Breed2</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Color1</th>\n",
       "      <th>Color2</th>\n",
       "      <th>Color3</th>\n",
       "      <th>MaturitySize</th>\n",
       "      <th>FurLength</th>\n",
       "      <th>Vaccinated</th>\n",
       "      <th>Dewormed</th>\n",
       "      <th>Sterilized</th>\n",
       "      <th>Health</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Fee</th>\n",
       "      <th>State</th>\n",
       "      <th>VideoAmt</th>\n",
       "      <th>PhotoAmt</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.150024</td>\n",
       "      <td>0.055922</td>\n",
       "      <td>-0.048857</td>\n",
       "      <td>0.062580</td>\n",
       "      <td>0.093889</td>\n",
       "      <td>0.250730</td>\n",
       "      <td>0.199668</td>\n",
       "      <td>-0.172627</td>\n",
       "      <td>-0.009966</td>\n",
       "      <td>0.110750</td>\n",
       "      <td>0.034795</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>-0.003571</td>\n",
       "      <td>0.046327</td>\n",
       "      <td>-0.045208</td>\n",
       "      <td>0.127153</td>\n",
       "      <td>-0.002877</td>\n",
       "      <td>0.050386</td>\n",
       "      <td>-0.096588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.150024</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.317141</td>\n",
       "      <td>-0.042328</td>\n",
       "      <td>-0.128883</td>\n",
       "      <td>0.089449</td>\n",
       "      <td>-0.043082</td>\n",
       "      <td>-0.051003</td>\n",
       "      <td>0.094532</td>\n",
       "      <td>0.156118</td>\n",
       "      <td>-0.138990</td>\n",
       "      <td>-0.056361</td>\n",
       "      <td>-0.194933</td>\n",
       "      <td>0.089627</td>\n",
       "      <td>-0.112622</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>0.024376</td>\n",
       "      <td>-0.021741</td>\n",
       "      <td>-0.081627</td>\n",
       "      <td>0.105835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breed1</th>\n",
       "      <td>0.055922</td>\n",
       "      <td>-0.317141</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.159807</td>\n",
       "      <td>0.070733</td>\n",
       "      <td>-0.030621</td>\n",
       "      <td>-0.013340</td>\n",
       "      <td>0.007075</td>\n",
       "      <td>-0.008280</td>\n",
       "      <td>-0.119483</td>\n",
       "      <td>0.042104</td>\n",
       "      <td>0.010842</td>\n",
       "      <td>0.062735</td>\n",
       "      <td>-0.036438</td>\n",
       "      <td>0.089211</td>\n",
       "      <td>-0.200489</td>\n",
       "      <td>-0.025743</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>0.034484</td>\n",
       "      <td>0.111364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Breed2</th>\n",
       "      <td>-0.048857</td>\n",
       "      <td>-0.042328</td>\n",
       "      <td>-0.159807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.071215</td>\n",
       "      <td>-0.020326</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.038584</td>\n",
       "      <td>0.054620</td>\n",
       "      <td>0.103603</td>\n",
       "      <td>0.010243</td>\n",
       "      <td>-0.001840</td>\n",
       "      <td>-0.006333</td>\n",
       "      <td>-0.021425</td>\n",
       "      <td>0.042083</td>\n",
       "      <td>0.008631</td>\n",
       "      <td>-0.044799</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>0.054457</td>\n",
       "      <td>-0.021178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.062580</td>\n",
       "      <td>-0.128883</td>\n",
       "      <td>0.070733</td>\n",
       "      <td>0.071215</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.114045</td>\n",
       "      <td>0.028391</td>\n",
       "      <td>0.256542</td>\n",
       "      <td>-0.093383</td>\n",
       "      <td>-0.032118</td>\n",
       "      <td>0.071064</td>\n",
       "      <td>0.091829</td>\n",
       "      <td>0.030318</td>\n",
       "      <td>-0.051646</td>\n",
       "      <td>0.496795</td>\n",
       "      <td>-0.049542</td>\n",
       "      <td>0.003222</td>\n",
       "      <td>0.020802</td>\n",
       "      <td>0.091525</td>\n",
       "      <td>0.057663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color1</th>\n",
       "      <td>0.093889</td>\n",
       "      <td>0.089449</td>\n",
       "      <td>-0.030621</td>\n",
       "      <td>-0.020326</td>\n",
       "      <td>-0.114045</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.114525</td>\n",
       "      <td>-0.281832</td>\n",
       "      <td>-0.025359</td>\n",
       "      <td>0.075806</td>\n",
       "      <td>-0.017658</td>\n",
       "      <td>-0.020026</td>\n",
       "      <td>-0.035473</td>\n",
       "      <td>0.032545</td>\n",
       "      <td>-0.110077</td>\n",
       "      <td>0.055972</td>\n",
       "      <td>0.030674</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>-0.041995</td>\n",
       "      <td>-0.045613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color2</th>\n",
       "      <td>0.250730</td>\n",
       "      <td>-0.043082</td>\n",
       "      <td>-0.013340</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.028391</td>\n",
       "      <td>-0.114525</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.084761</td>\n",
       "      <td>-0.079657</td>\n",
       "      <td>-0.011525</td>\n",
       "      <td>0.027130</td>\n",
       "      <td>0.008896</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>-0.002449</td>\n",
       "      <td>0.022109</td>\n",
       "      <td>-0.021506</td>\n",
       "      <td>0.034442</td>\n",
       "      <td>0.028056</td>\n",
       "      <td>0.059475</td>\n",
       "      <td>-0.041183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color3</th>\n",
       "      <td>0.199668</td>\n",
       "      <td>-0.051003</td>\n",
       "      <td>0.007075</td>\n",
       "      <td>0.038584</td>\n",
       "      <td>0.256542</td>\n",
       "      <td>-0.281832</td>\n",
       "      <td>0.084761</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.051689</td>\n",
       "      <td>0.011624</td>\n",
       "      <td>0.054279</td>\n",
       "      <td>0.049366</td>\n",
       "      <td>0.029254</td>\n",
       "      <td>-0.031123</td>\n",
       "      <td>0.269975</td>\n",
       "      <td>-0.017541</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>0.027171</td>\n",
       "      <td>0.103766</td>\n",
       "      <td>-0.003366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MaturitySize</th>\n",
       "      <td>-0.172627</td>\n",
       "      <td>0.094532</td>\n",
       "      <td>-0.008280</td>\n",
       "      <td>0.054620</td>\n",
       "      <td>-0.093383</td>\n",
       "      <td>-0.025359</td>\n",
       "      <td>-0.079657</td>\n",
       "      <td>-0.051689</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099199</td>\n",
       "      <td>-0.074013</td>\n",
       "      <td>-0.058920</td>\n",
       "      <td>-0.057781</td>\n",
       "      <td>-0.015047</td>\n",
       "      <td>-0.043203</td>\n",
       "      <td>0.045344</td>\n",
       "      <td>-0.060916</td>\n",
       "      <td>0.023799</td>\n",
       "      <td>0.011683</td>\n",
       "      <td>0.047770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FurLength</th>\n",
       "      <td>-0.009966</td>\n",
       "      <td>0.156118</td>\n",
       "      <td>-0.119483</td>\n",
       "      <td>0.103603</td>\n",
       "      <td>-0.032118</td>\n",
       "      <td>0.075806</td>\n",
       "      <td>-0.011525</td>\n",
       "      <td>0.011624</td>\n",
       "      <td>0.099199</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012485</td>\n",
       "      <td>0.013764</td>\n",
       "      <td>0.028363</td>\n",
       "      <td>0.035957</td>\n",
       "      <td>-0.039007</td>\n",
       "      <td>0.159591</td>\n",
       "      <td>-0.025696</td>\n",
       "      <td>-0.016959</td>\n",
       "      <td>-0.025926</td>\n",
       "      <td>-0.083989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vaccinated</th>\n",
       "      <td>0.110750</td>\n",
       "      <td>-0.138990</td>\n",
       "      <td>0.042104</td>\n",
       "      <td>0.010243</td>\n",
       "      <td>0.071064</td>\n",
       "      <td>-0.017658</td>\n",
       "      <td>0.027130</td>\n",
       "      <td>0.054279</td>\n",
       "      <td>-0.074013</td>\n",
       "      <td>-0.012485</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.726174</td>\n",
       "      <td>0.473764</td>\n",
       "      <td>0.080417</td>\n",
       "      <td>0.130509</td>\n",
       "      <td>-0.119388</td>\n",
       "      <td>0.035170</td>\n",
       "      <td>-0.035604</td>\n",
       "      <td>-0.049141</td>\n",
       "      <td>-0.062681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dewormed</th>\n",
       "      <td>0.034795</td>\n",
       "      <td>-0.056361</td>\n",
       "      <td>0.010842</td>\n",
       "      <td>-0.001840</td>\n",
       "      <td>0.091829</td>\n",
       "      <td>-0.020026</td>\n",
       "      <td>0.008896</td>\n",
       "      <td>0.049366</td>\n",
       "      <td>-0.058920</td>\n",
       "      <td>0.013764</td>\n",
       "      <td>0.726174</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.433507</td>\n",
       "      <td>0.071565</td>\n",
       "      <td>0.141308</td>\n",
       "      <td>-0.101096</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>-0.042342</td>\n",
       "      <td>-0.108417</td>\n",
       "      <td>-0.014050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sterilized</th>\n",
       "      <td>0.006710</td>\n",
       "      <td>-0.194933</td>\n",
       "      <td>0.062735</td>\n",
       "      <td>-0.006333</td>\n",
       "      <td>0.030318</td>\n",
       "      <td>-0.035473</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>0.029254</td>\n",
       "      <td>-0.057781</td>\n",
       "      <td>0.028363</td>\n",
       "      <td>0.473764</td>\n",
       "      <td>0.433507</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058490</td>\n",
       "      <td>0.098085</td>\n",
       "      <td>-0.061719</td>\n",
       "      <td>0.011650</td>\n",
       "      <td>-0.014732</td>\n",
       "      <td>-0.069159</td>\n",
       "      <td>-0.095836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Health</th>\n",
       "      <td>-0.003571</td>\n",
       "      <td>0.089627</td>\n",
       "      <td>-0.036438</td>\n",
       "      <td>-0.021425</td>\n",
       "      <td>-0.051646</td>\n",
       "      <td>0.032545</td>\n",
       "      <td>-0.002449</td>\n",
       "      <td>-0.031123</td>\n",
       "      <td>-0.015047</td>\n",
       "      <td>0.035957</td>\n",
       "      <td>0.080417</td>\n",
       "      <td>0.071565</td>\n",
       "      <td>0.058490</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034026</td>\n",
       "      <td>-0.003993</td>\n",
       "      <td>0.026480</td>\n",
       "      <td>-0.017938</td>\n",
       "      <td>-0.022009</td>\n",
       "      <td>0.027208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Quantity</th>\n",
       "      <td>0.046327</td>\n",
       "      <td>-0.112622</td>\n",
       "      <td>0.089211</td>\n",
       "      <td>0.042083</td>\n",
       "      <td>0.496795</td>\n",
       "      <td>-0.110077</td>\n",
       "      <td>0.022109</td>\n",
       "      <td>0.269975</td>\n",
       "      <td>-0.043203</td>\n",
       "      <td>-0.039007</td>\n",
       "      <td>0.130509</td>\n",
       "      <td>0.141308</td>\n",
       "      <td>0.098085</td>\n",
       "      <td>-0.034026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.062957</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.131904</td>\n",
       "      <td>0.074705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fee</th>\n",
       "      <td>-0.045208</td>\n",
       "      <td>0.099678</td>\n",
       "      <td>-0.200489</td>\n",
       "      <td>0.008631</td>\n",
       "      <td>-0.049542</td>\n",
       "      <td>0.055972</td>\n",
       "      <td>-0.021506</td>\n",
       "      <td>-0.017541</td>\n",
       "      <td>0.045344</td>\n",
       "      <td>0.159591</td>\n",
       "      <td>-0.119388</td>\n",
       "      <td>-0.101096</td>\n",
       "      <td>-0.061719</td>\n",
       "      <td>-0.003993</td>\n",
       "      <td>-0.062957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>-0.007137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>State</th>\n",
       "      <td>0.127153</td>\n",
       "      <td>0.024376</td>\n",
       "      <td>-0.025743</td>\n",
       "      <td>-0.044799</td>\n",
       "      <td>0.003222</td>\n",
       "      <td>0.030674</td>\n",
       "      <td>0.034442</td>\n",
       "      <td>0.003037</td>\n",
       "      <td>-0.060916</td>\n",
       "      <td>-0.025696</td>\n",
       "      <td>0.035170</td>\n",
       "      <td>0.000197</td>\n",
       "      <td>0.011650</td>\n",
       "      <td>0.026480</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>-0.020523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026038</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>0.018257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VideoAmt</th>\n",
       "      <td>-0.002877</td>\n",
       "      <td>-0.021741</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>0.004433</td>\n",
       "      <td>0.020802</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.028056</td>\n",
       "      <td>0.027171</td>\n",
       "      <td>0.023799</td>\n",
       "      <td>-0.016959</td>\n",
       "      <td>-0.035604</td>\n",
       "      <td>-0.042342</td>\n",
       "      <td>-0.014732</td>\n",
       "      <td>-0.017938</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>-0.026038</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.250728</td>\n",
       "      <td>-0.008259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PhotoAmt</th>\n",
       "      <td>0.050386</td>\n",
       "      <td>-0.081627</td>\n",
       "      <td>0.034484</td>\n",
       "      <td>0.054457</td>\n",
       "      <td>0.091525</td>\n",
       "      <td>-0.041995</td>\n",
       "      <td>0.059475</td>\n",
       "      <td>0.103766</td>\n",
       "      <td>0.011683</td>\n",
       "      <td>-0.025926</td>\n",
       "      <td>-0.049141</td>\n",
       "      <td>-0.108417</td>\n",
       "      <td>-0.069159</td>\n",
       "      <td>-0.022009</td>\n",
       "      <td>0.131904</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>0.007630</td>\n",
       "      <td>0.250728</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.024016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdoptionSpeed</th>\n",
       "      <td>-0.096588</td>\n",
       "      <td>0.105835</td>\n",
       "      <td>0.111364</td>\n",
       "      <td>-0.021178</td>\n",
       "      <td>0.057663</td>\n",
       "      <td>-0.045613</td>\n",
       "      <td>-0.041183</td>\n",
       "      <td>-0.003366</td>\n",
       "      <td>0.047770</td>\n",
       "      <td>-0.083989</td>\n",
       "      <td>-0.062681</td>\n",
       "      <td>-0.014050</td>\n",
       "      <td>-0.095836</td>\n",
       "      <td>0.027208</td>\n",
       "      <td>0.074705</td>\n",
       "      <td>-0.007137</td>\n",
       "      <td>0.018257</td>\n",
       "      <td>-0.008259</td>\n",
       "      <td>-0.024016</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Type       Age    Breed1    Breed2    Gender    Color1  \\\n",
       "Type           1.000000 -0.150024  0.055922 -0.048857  0.062580  0.093889   \n",
       "Age           -0.150024  1.000000 -0.317141 -0.042328 -0.128883  0.089449   \n",
       "Breed1         0.055922 -0.317141  1.000000 -0.159807  0.070733 -0.030621   \n",
       "Breed2        -0.048857 -0.042328 -0.159807  1.000000  0.071215 -0.020326   \n",
       "Gender         0.062580 -0.128883  0.070733  0.071215  1.000000 -0.114045   \n",
       "Color1         0.093889  0.089449 -0.030621 -0.020326 -0.114045  1.000000   \n",
       "Color2         0.250730 -0.043082 -0.013340  0.004285  0.028391 -0.114525   \n",
       "Color3         0.199668 -0.051003  0.007075  0.038584  0.256542 -0.281832   \n",
       "MaturitySize  -0.172627  0.094532 -0.008280  0.054620 -0.093383 -0.025359   \n",
       "FurLength     -0.009966  0.156118 -0.119483  0.103603 -0.032118  0.075806   \n",
       "Vaccinated     0.110750 -0.138990  0.042104  0.010243  0.071064 -0.017658   \n",
       "Dewormed       0.034795 -0.056361  0.010842 -0.001840  0.091829 -0.020026   \n",
       "Sterilized     0.006710 -0.194933  0.062735 -0.006333  0.030318 -0.035473   \n",
       "Health        -0.003571  0.089627 -0.036438 -0.021425 -0.051646  0.032545   \n",
       "Quantity       0.046327 -0.112622  0.089211  0.042083  0.496795 -0.110077   \n",
       "Fee           -0.045208  0.099678 -0.200489  0.008631 -0.049542  0.055972   \n",
       "State          0.127153  0.024376 -0.025743 -0.044799  0.003222  0.030674   \n",
       "VideoAmt      -0.002877 -0.021741  0.009460  0.004433  0.020802  0.000661   \n",
       "PhotoAmt       0.050386 -0.081627  0.034484  0.054457  0.091525 -0.041995   \n",
       "AdoptionSpeed -0.096588  0.105835  0.111364 -0.021178  0.057663 -0.045613   \n",
       "\n",
       "                 Color2    Color3  MaturitySize  FurLength  Vaccinated  \\\n",
       "Type           0.250730  0.199668     -0.172627  -0.009966    0.110750   \n",
       "Age           -0.043082 -0.051003      0.094532   0.156118   -0.138990   \n",
       "Breed1        -0.013340  0.007075     -0.008280  -0.119483    0.042104   \n",
       "Breed2         0.004285  0.038584      0.054620   0.103603    0.010243   \n",
       "Gender         0.028391  0.256542     -0.093383  -0.032118    0.071064   \n",
       "Color1        -0.114525 -0.281832     -0.025359   0.075806   -0.017658   \n",
       "Color2         1.000000  0.084761     -0.079657  -0.011525    0.027130   \n",
       "Color3         0.084761  1.000000     -0.051689   0.011624    0.054279   \n",
       "MaturitySize  -0.079657 -0.051689      1.000000   0.099199   -0.074013   \n",
       "FurLength     -0.011525  0.011624      0.099199   1.000000   -0.012485   \n",
       "Vaccinated     0.027130  0.054279     -0.074013  -0.012485    1.000000   \n",
       "Dewormed       0.008896  0.049366     -0.058920   0.013764    0.726174   \n",
       "Sterilized     0.004854  0.029254     -0.057781   0.028363    0.473764   \n",
       "Health        -0.002449 -0.031123     -0.015047   0.035957    0.080417   \n",
       "Quantity       0.022109  0.269975     -0.043203  -0.039007    0.130509   \n",
       "Fee           -0.021506 -0.017541      0.045344   0.159591   -0.119388   \n",
       "State          0.034442  0.003037     -0.060916  -0.025696    0.035170   \n",
       "VideoAmt       0.028056  0.027171      0.023799  -0.016959   -0.035604   \n",
       "PhotoAmt       0.059475  0.103766      0.011683  -0.025926   -0.049141   \n",
       "AdoptionSpeed -0.041183 -0.003366      0.047770  -0.083989   -0.062681   \n",
       "\n",
       "               Dewormed  Sterilized    Health  Quantity       Fee     State  \\\n",
       "Type           0.034795    0.006710 -0.003571  0.046327 -0.045208  0.127153   \n",
       "Age           -0.056361   -0.194933  0.089627 -0.112622  0.099678  0.024376   \n",
       "Breed1         0.010842    0.062735 -0.036438  0.089211 -0.200489 -0.025743   \n",
       "Breed2        -0.001840   -0.006333 -0.021425  0.042083  0.008631 -0.044799   \n",
       "Gender         0.091829    0.030318 -0.051646  0.496795 -0.049542  0.003222   \n",
       "Color1        -0.020026   -0.035473  0.032545 -0.110077  0.055972  0.030674   \n",
       "Color2         0.008896    0.004854 -0.002449  0.022109 -0.021506  0.034442   \n",
       "Color3         0.049366    0.029254 -0.031123  0.269975 -0.017541  0.003037   \n",
       "MaturitySize  -0.058920   -0.057781 -0.015047 -0.043203  0.045344 -0.060916   \n",
       "FurLength      0.013764    0.028363  0.035957 -0.039007  0.159591 -0.025696   \n",
       "Vaccinated     0.726174    0.473764  0.080417  0.130509 -0.119388  0.035170   \n",
       "Dewormed       1.000000    0.433507  0.071565  0.141308 -0.101096  0.000197   \n",
       "Sterilized     0.433507    1.000000  0.058490  0.098085 -0.061719  0.011650   \n",
       "Health         0.071565    0.058490  1.000000 -0.034026 -0.003993  0.026480   \n",
       "Quantity       0.141308    0.098085 -0.034026  1.000000 -0.062957  0.000191   \n",
       "Fee           -0.101096   -0.061719 -0.003993 -0.062957  1.000000 -0.020523   \n",
       "State          0.000197    0.011650  0.026480  0.000191 -0.020523  1.000000   \n",
       "VideoAmt      -0.042342   -0.014732 -0.017938  0.002043  0.000955 -0.026038   \n",
       "PhotoAmt      -0.108417   -0.069159 -0.022009  0.131904  0.006155  0.007630   \n",
       "AdoptionSpeed -0.014050   -0.095836  0.027208  0.074705 -0.007137  0.018257   \n",
       "\n",
       "               VideoAmt  PhotoAmt  AdoptionSpeed  \n",
       "Type          -0.002877  0.050386      -0.096588  \n",
       "Age           -0.021741 -0.081627       0.105835  \n",
       "Breed1         0.009460  0.034484       0.111364  \n",
       "Breed2         0.004433  0.054457      -0.021178  \n",
       "Gender         0.020802  0.091525       0.057663  \n",
       "Color1         0.000661 -0.041995      -0.045613  \n",
       "Color2         0.028056  0.059475      -0.041183  \n",
       "Color3         0.027171  0.103766      -0.003366  \n",
       "MaturitySize   0.023799  0.011683       0.047770  \n",
       "FurLength     -0.016959 -0.025926      -0.083989  \n",
       "Vaccinated    -0.035604 -0.049141      -0.062681  \n",
       "Dewormed      -0.042342 -0.108417      -0.014050  \n",
       "Sterilized    -0.014732 -0.069159      -0.095836  \n",
       "Health        -0.017938 -0.022009       0.027208  \n",
       "Quantity       0.002043  0.131904       0.074705  \n",
       "Fee            0.000955  0.006155      -0.007137  \n",
       "State         -0.026038  0.007630       0.018257  \n",
       "VideoAmt       1.000000  0.250728      -0.008259  \n",
       "PhotoAmt       0.250728  1.000000      -0.024016  \n",
       "AdoptionSpeed -0.008259 -0.024016       1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Correlation\n",
    "# df_temp = df_train.filter(['log_price','accommodates', 'bathrooms', 'bedrooms', 'beds', 'Real Bed', 'Shared room', \n",
    "#                            'Entire home/apt', 'Private room', 'cleaning_fee', 'review_scores_rating', \n",
    "#                            'host_since_year', 'Boston', 'Chicago', 'DC', 'LA', 'NYC', 'SF', 'c_distance', 'Condominium', 'pets', 'event',\n",
    "#                           'kitchen', 'heating', 'gym', 'elevator', 'pool', '#amenities'], axis=1)\n",
    "df_train.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5442\n",
      "2    4558\n",
      "Name: Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['Type'].value_counts())\n",
    "\n",
    "# apply dummies on the training set\n",
    "col = 'Type'\n",
    "df_dummies = pd.get_dummies(df_train[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_train = pd.concat([df_train, df_dummies], axis=1)\n",
    "\n",
    "# apply the same dummies on the test set\n",
    "col = 'Type'\n",
    "df_dummies = pd.get_dummies(df_test[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_test = pd.concat([df_test, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lucky      45\n",
       "Baby       44\n",
       "Brownie    43\n",
       "No Name    39\n",
       "Mimi       35\n",
       "Puppy      32\n",
       "Kitty      28\n",
       "Max        27\n",
       "Kittens    25\n",
       "Snowy      25\n",
       "Name: Name, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_name= df_train['Name'].value_counts().head(10)\n",
    "top_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       24.0\n",
       "1        6.0\n",
       "2       35.0\n",
       "3        NaN\n",
       "4       15.0\n",
       "5        4.0\n",
       "6        4.0\n",
       "7       21.0\n",
       "8        NaN\n",
       "9        7.0\n",
       "10      24.0\n",
       "11       5.0\n",
       "12       6.0\n",
       "13       4.0\n",
       "14       5.0\n",
       "15      25.0\n",
       "16       NaN\n",
       "17       9.0\n",
       "18       NaN\n",
       "19       5.0\n",
       "20       4.0\n",
       "21       NaN\n",
       "22       6.0\n",
       "23       5.0\n",
       "24       5.0\n",
       "25      20.0\n",
       "26       6.0\n",
       "27       4.0\n",
       "28       5.0\n",
       "29       5.0\n",
       "        ... \n",
       "9970    10.0\n",
       "9971     7.0\n",
       "9972     4.0\n",
       "9973    25.0\n",
       "9974    35.0\n",
       "9975    26.0\n",
       "9976     4.0\n",
       "9977     5.0\n",
       "9978     7.0\n",
       "9979    18.0\n",
       "9980     5.0\n",
       "9981    17.0\n",
       "9982     3.0\n",
       "9983     7.0\n",
       "9984     4.0\n",
       "9985     8.0\n",
       "9986    35.0\n",
       "9987     6.0\n",
       "9988     6.0\n",
       "9989     6.0\n",
       "9990     4.0\n",
       "9991     6.0\n",
       "9992     8.0\n",
       "9993    27.0\n",
       "9994     4.0\n",
       "9995     4.0\n",
       "9996     NaN\n",
       "9997     8.0\n",
       "9998     6.0\n",
       "9999     NaN\n",
       "Name: Name, Length: 10000, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['Name'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bew feature with Name or No-Name\n",
    "df_train['Name Status'] = np.where((df_train['Name'].isnull()) | (df_train['Name'].str.len()<=2), 0, 1)\n",
    "\n",
    "# apply the same dummies on the test set\n",
    "df_test['Name Status'] = np.where((df_test['Name'].isnull())  | (df_test['Name'].str.len()<=2), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_names = ['Lucky', 'Baby', 'Brownie', 'No Name', 'Mimi', 'Puppy', 'Kitty', 'Max', 'Kittens', 'Snowy']\n",
    "\n",
    "# df_train['Lucky'] = np.where(df_train['Name'].str.contains(\"Lucky\")==True, '1', '0')\n",
    "# df_train['Lucky'] = df_train['Lucky'].astype(int)\n",
    "\n",
    "# df_test['Lucky'] = np.where(df_test['Name'].str.contains(\"Lucky\")==True, '1', '0')\n",
    "# df_test['Lucky'] = df_test['Lucky'].astype(int)\n",
    "\n",
    "# df_train['Baby'] = np.where(df_train['Name'].str.contains(\"Baby\")==True, '1', '0')\n",
    "# df_train['Baby'] = df_train['Baby'].astype(int)\n",
    "\n",
    "# df_test['Baby'] = np.where(df_test['Name'].str.contains(\"Baby\")==True, '1', '0')\n",
    "# df_test['Baby'] = df_test['Baby'].astype(int)\n",
    "\n",
    "# df_train['Brownie'] = np.where(df_train['Name'].str.contains(\"Brownie\")==True, '1', '0')\n",
    "# df_train['Brownie'] = df_train['Brownie'].astype(int)\n",
    "\n",
    "# df_test['Brownie'] = np.where(df_test['Name'].str.contains(\"Brownie\")==True, '1', '0')\n",
    "# df_test['Brownie'] = df_test['Brownie'].astype(int)\n",
    "\n",
    "# df_train['Mimi'] = np.where(df_train['Name'].str.contains(\"Mimi\")==True, '1', '0')\n",
    "# df_train['Mimi'] = df_train['Mimi'].astype(int)\n",
    "\n",
    "# df_test['Mimi'] = np.where(df_test['Name'].str.contains(\"Mimi\")==True, '1', '0')\n",
    "# df_test['Mimi'] = df_test['Mimi'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2      2329\n",
      "1      1539\n",
      "3      1310\n",
      "4       726\n",
      "12      643\n",
      "24      444\n",
      "6       390\n",
      "5       373\n",
      "36      290\n",
      "8       203\n",
      "7       177\n",
      "48      158\n",
      "60      141\n",
      "0       121\n",
      "10      119\n",
      "9       119\n",
      "18      115\n",
      "72       77\n",
      "11       65\n",
      "84       64\n",
      "14       57\n",
      "15       47\n",
      "17       40\n",
      "30       38\n",
      "16       30\n",
      "13       29\n",
      "96       27\n",
      "120      20\n",
      "20       20\n",
      "29       20\n",
      "       ... \n",
      "52        2\n",
      "92        2\n",
      "56        2\n",
      "180       2\n",
      "212       2\n",
      "77        2\n",
      "64        2\n",
      "168       1\n",
      "144       1\n",
      "112       1\n",
      "88        1\n",
      "255       1\n",
      "81        1\n",
      "74        1\n",
      "47        1\n",
      "238       1\n",
      "102       1\n",
      "117       1\n",
      "69        1\n",
      "45        1\n",
      "156       1\n",
      "68        1\n",
      "44        1\n",
      "135       1\n",
      "123       1\n",
      "75        1\n",
      "43        1\n",
      "122       1\n",
      "82        1\n",
      "147       1\n",
      "Name: Age, Length: 99, dtype: int64\n",
      "Unique Values in the Column: ['M1' 'M13-M24' 'M168+' 'M2' 'M212-M168' 'M25-M72' 'M3' 'M4' 'M5' 'M6'\n",
      " 'M7-M12' 'M73-M120']\n"
     ]
    }
   ],
   "source": [
    "df_train['Age'] = df_train['Age'].astype(int)\n",
    "\n",
    "print(df_train['Age'].value_counts())\n",
    "\n",
    "# print('mean', np.mean(df_train['Age']))\n",
    "# print('std', np.std(df_train['Age']))\n",
    "# plt.hist(df_train['Age'], bins=30)\n",
    "# plt.show()\n",
    "\n",
    "# convert Age into groups\n",
    "def convert_age_group(val):\n",
    "    if val ==1:\n",
    "        return 'M1'\n",
    "    elif val ==2:\n",
    "        return 'M2'\n",
    "    elif val ==3:\n",
    "        return 'M3'\n",
    "    elif val ==4:\n",
    "        return 'M4'\n",
    "    elif val ==5:\n",
    "        return 'M5'\n",
    "    elif val ==6:\n",
    "        return 'M6'\n",
    "    elif val >=7 and val <= 12:\n",
    "        return 'M7-M12'\n",
    "    elif val >=13 and val <= 24:\n",
    "        return 'M13-M24'\n",
    "    elif val >= 25 and val <= 72:\n",
    "        return 'M25-M72'\n",
    "    elif val >= 73 and val <= 120:\n",
    "        return 'M73-M120'\n",
    "    elif val >= 121 and val <= 168:\n",
    "        return 'M212-M168'\n",
    "    else:\n",
    "        return 'M168+'\n",
    "        \n",
    "df_train['Age'] = df_train['Age'].apply(convert_age_group)\n",
    "print ('Unique Values in the Column:', np.unique(df_train['Age']))\n",
    "# print(df_train['review_scores_rating'].value_counts())\n",
    "\n",
    "# Create new features from review_scores_rating\n",
    "convert_age_group = pd.get_dummies(df_train['Age']).astype(int)\n",
    "df_train = pd.concat([df_train, convert_age_group], axis=1)\n",
    "\n",
    "# # Delete column from df_train\n",
    "# del df_train['Age']\n",
    "\n",
    "# apply the same dummies on the test set\n",
    "df_test['Age'] = df_test['Age'].astype(int)\n",
    "\n",
    "# convert Age into groups\n",
    "def convert_age_group(val):\n",
    "    if val ==1:\n",
    "        return 'M1'\n",
    "    elif val ==2:\n",
    "        return 'M2'\n",
    "    elif val ==3:\n",
    "        return 'M3'\n",
    "    elif val ==4:\n",
    "        return 'M4'\n",
    "    elif val ==5:\n",
    "        return 'M5'\n",
    "    elif val ==6:\n",
    "        return 'M6'\n",
    "    elif val >=7 and val <= 12:\n",
    "        return 'M7-M12'\n",
    "    elif val >=13 and val <= 24:\n",
    "        return 'M13-M24'\n",
    "    elif val >= 25 and val <= 72:\n",
    "        return 'M25-M72'\n",
    "    elif val >= 73 and val <= 120:\n",
    "        return 'M73-M120'\n",
    "    elif val >= 121 and val <= 168:\n",
    "        return 'M212-M168'\n",
    "    else:\n",
    "        return 'M168+'\n",
    "            \n",
    "df_test['Age'] = df_test['Age'].apply(convert_age_group)\n",
    "\n",
    "# Create new features from review_scores_rating\n",
    "convert_age_group = pd.get_dummies(df_test['Age']).astype(int)\n",
    "df_test = pd.concat([df_test, convert_age_group], axis=1)\n",
    "\n",
    "# # Delete column from df_train\n",
    "# del df_test['Age']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Breed1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307    3979\n",
      "266    2423\n",
      "265     840\n",
      "299     230\n",
      "264     188\n",
      "292     162\n",
      "285     152\n",
      "141     137\n",
      "205     124\n",
      "179     117\n",
      "109      97\n",
      "218      96\n",
      "243      70\n",
      "103      70\n",
      "254      64\n",
      "189      61\n",
      "213      60\n",
      "20       56\n",
      "283      51\n",
      "78       46\n",
      "Name: Breed1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['Breed1'].value_counts().head(20))\n",
    "\n",
    "# # apply dummies on the training set\n",
    "# col = 'Breed1'\n",
    "# df_dummies = pd.get_dummies(df_train[col])\n",
    "# df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "# df_train = pd.concat([df_train, df_dummies], axis=1)\n",
    "\n",
    "# # apply the same dummies on the test set\n",
    "# col = 'Breed1'\n",
    "# df_dummies = pd.get_dummies(df_test[col])\n",
    "# df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "# df_test = pd.concat([df_test, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values in the Column: ['T1' 'T10' 'T11' 'T12' 'T13' 'T14' 'T15' 'T16' 'T17' 'T18' 'T19' 'T2'\n",
      " 'T20' 'T3' 'T4' 'T5' 'T6' 'T7' 'T8' 'T9' 'TX']\n"
     ]
    }
   ],
   "source": [
    "# convert Breed1 into groups\n",
    "def convert_Breed1(val):\n",
    "    if val == 307:\n",
    "        return 'T1'\n",
    "    elif val == 266:\n",
    "        return 'T2'\n",
    "    elif val == 265:\n",
    "        return 'T3'\n",
    "    elif val == 299:\n",
    "        return 'T4'\n",
    "    elif val == 264:\n",
    "        return 'T5'\n",
    "    elif val == 292:\n",
    "        return 'T6'\n",
    "    elif val == 285:\n",
    "        return 'T7'\n",
    "    elif val == 141:\n",
    "        return 'T8'\n",
    "    elif val == 205:\n",
    "        return 'T9'\n",
    "    elif val == 179:\n",
    "        return 'T10'\n",
    "    elif val == 109:\n",
    "        return 'T11'\n",
    "    elif val == 218:\n",
    "        return 'T12'\n",
    "    elif val == 243:\n",
    "        return 'T13'\n",
    "    elif val == 103:\n",
    "        return 'T14'\n",
    "    elif val == 254:\n",
    "        return 'T15'\n",
    "    elif val == 189:\n",
    "        return 'T16'\n",
    "    elif val == 213:\n",
    "        return 'T17'\n",
    "    elif val == 20:\n",
    "        return 'T18'\n",
    "    elif val == 283:\n",
    "        return 'T19'\n",
    "    elif val == 78:\n",
    "        return 'T20'\n",
    "    else:\n",
    "        return 'TX'\n",
    "        \n",
    "df_train['Breed1'] = df_train['Breed1'].apply(convert_Breed1)\n",
    "print ('Unique Values in the Column:', np.unique(df_train['Breed1']))\n",
    "# print(df_train['review_scores_rating'].value_counts())\n",
    "\n",
    "# Create new features from review_scores_rating\n",
    "convert_Breed1 = pd.get_dummies(df_train['Breed1']).astype(int)\n",
    "df_train = pd.concat([df_train, convert_Breed1], axis=1)\n",
    "\n",
    "# apply the same dummies on the test set\n",
    "\n",
    "# convert Breed1 into groups\n",
    "def convert_Breed1(val):\n",
    "    if val == 307:\n",
    "        return 'T1'\n",
    "    elif val == 266:\n",
    "        return 'T2'\n",
    "    elif val == 265:\n",
    "        return 'T3'\n",
    "    elif val == 299:\n",
    "        return 'T4'\n",
    "    elif val == 264:\n",
    "        return 'T5'\n",
    "    elif val == 292:\n",
    "        return 'T6'\n",
    "    elif val == 285:\n",
    "        return 'T7'\n",
    "    elif val == 141:\n",
    "        return 'T8'\n",
    "    elif val == 205:\n",
    "        return 'T9'\n",
    "    elif val == 179:\n",
    "        return 'T10'\n",
    "    elif val == 109:\n",
    "        return 'T11'\n",
    "    elif val == 218:\n",
    "        return 'T12'\n",
    "    elif val == 243:\n",
    "        return 'T13'\n",
    "    elif val == 103:\n",
    "        return 'T14'\n",
    "    elif val == 254:\n",
    "        return 'T15'\n",
    "    elif val == 189:\n",
    "        return 'T16'\n",
    "    elif val == 213:\n",
    "        return 'T17'\n",
    "    elif val == 20:\n",
    "        return 'T18'\n",
    "    elif val == 283:\n",
    "        return 'T19'\n",
    "    elif val == 78:\n",
    "        return 'T20'\n",
    "    else:\n",
    "        return 'TX'\n",
    "            \n",
    "df_test['Breed1'] = df_test['Breed1'].apply(convert_Breed1)\n",
    "\n",
    "# Create new features from review_scores_rating\n",
    "convert_Breed1 = pd.get_dummies(df_test['Breed1']).astype(int)\n",
    "df_test = pd.concat([df_test, convert_Breed1], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Breed2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      7212\n",
      "307    1144\n",
      "266     379\n",
      "265     212\n",
      "264      87\n",
      "299      85\n",
      "292      79\n",
      "218      65\n",
      "141      57\n",
      "285      54\n",
      "Name: Breed2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['Breed2'].value_counts().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert Breed1 into groups\n",
    "# def convert_Breed2(val):\n",
    "#     if val == 0:\n",
    "#         return 'B2-1'\n",
    "#     elif val == 307:\n",
    "#         return 'B2-2'\n",
    "#     elif val == 266:\n",
    "#         return 'B2-3'\n",
    "#     elif val == 265:\n",
    "#         return 'B2-4'\n",
    "#     elif val == 264:\n",
    "#         return 'B2-5'\n",
    "#     else:\n",
    "#         return 'B2-X'\n",
    "        \n",
    "# df_train['Breed2'] = df_train['Breed2'].apply(convert_Breed2)\n",
    "# print ('Unique Values in the Column:', np.unique(df_train['Breed2']))\n",
    "# # print(df_train['review_scores_rating'].value_counts())\n",
    "\n",
    "# # Create new features from review_scores_rating\n",
    "# convert_Breed2 = pd.get_dummies(df_train['Breed2']).astype(int)\n",
    "# df_train = pd.concat([df_train, convert_Breed2], axis=1)\n",
    "\n",
    "# # apply the same dummies on the test set\n",
    "\n",
    "# # convert Breed1 into groups\n",
    "# def convert_Breed2(val):\n",
    "#     if val == 0:\n",
    "#         return 'B2-1'\n",
    "#     elif val == 307:\n",
    "#         return 'B2-2'\n",
    "#     elif val == 266:\n",
    "#         return 'B2-3'\n",
    "#     elif val == 265:\n",
    "#         return 'B2-4'\n",
    "#     elif val == 264:\n",
    "#         return 'B2-5'\n",
    "#     else:\n",
    "#         return 'B2-X'\n",
    "            \n",
    "# df_test['Breed2'] = df_test['Breed2'].apply(convert_Breed2)\n",
    "\n",
    "# # Create new features from review_scores_rating\n",
    "# convert_Breed2 = pd.get_dummies(df_test['Breed2']).astype(int)\n",
    "# df_test = pd.concat([df_test, convert_Breed2], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    4866\n",
      "1    3685\n",
      "3    1449\n",
      "Name: Gender, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['Gender'].value_counts())\n",
    "\n",
    "# apply dummies on the training set\n",
    "col = 'Gender'\n",
    "df_dummies = pd.get_dummies(df_train[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_train = pd.concat([df_train, df_dummies], axis=1)\n",
    "\n",
    "# apply the same dummies on the test set\n",
    "col = 'Gender'\n",
    "df_dummies = pd.get_dummies(df_test[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_test = pd.concat([df_test, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Color1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['Color1'] = df_train['Color1'].astype(str)\n",
    "# df_train['Color2'] = df_train['Color2'].astype(str)\n",
    "# df_train['Color3'] = df_train['Color3'].astype(str)\n",
    "\n",
    "# df_train['Color'] = df_train['Color1'] + df_train['Color2'] + df_train['Color3']\n",
    "\n",
    "# print(df_train['Color'].value_counts())\n",
    "\n",
    "# df_test['Color1'] = df_test['Color1'].astype(str)\n",
    "# df_test['Color2'] = df_test['Color2'].astype(str)\n",
    "# df_test['Color3'] = df_test['Color3'].astype(str)\n",
    "\n",
    "# df_test['Color'] = df_test['Color1'] + df_test['Color2'] + df_test['Color3']\n",
    "\n",
    "\n",
    "# # apply dummies on the training set\n",
    "# col = 'Color'\n",
    "# df_dummies = pd.get_dummies(df_train[col])\n",
    "# df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "# df_train = pd.concat([df_train, df_dummies], axis=1)\n",
    "\n",
    "# # apply the same dummies on the test set\n",
    "# col = 'Color'\n",
    "# df_dummies = pd.get_dummies(df_test[col])\n",
    "# df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "# df_test = pd.concat([df_test, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train['Color1'].value_counts())\n",
    "\n",
    "# # apply dummies on the training set\n",
    "# col = 'Color1'\n",
    "# df_dummies = pd.get_dummies(df_train[col])\n",
    "# df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "# df_train = pd.concat([df_train, df_dummies], axis=1)\n",
    "\n",
    "# # apply the same dummies on the test set\n",
    "# col = 'Color1'\n",
    "# df_dummies = pd.get_dummies(df_test[col])\n",
    "# df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "# df_test = pd.concat([df_test, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Color 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train['Color2'].value_counts())\n",
    "\n",
    "# # apply dummies on the training set\n",
    "# col = 'Color2'\n",
    "# df_dummies = pd.get_dummies(df_train[col])\n",
    "# df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "# df_train = pd.concat([df_train, df_dummies], axis=1)\n",
    "\n",
    "# # apply the same dummies on the test set\n",
    "# col = 'Color2'\n",
    "# df_dummies = pd.get_dummies(df_test[col])\n",
    "# df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "# df_test = pd.concat([df_test, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Color3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train['Color3'].value_counts())\n",
    "\n",
    "# # apply dummies on the training set\n",
    "# col = 'Color3'\n",
    "# df_dummies = pd.get_dummies(df_train[col])\n",
    "# df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "# df_train = pd.concat([df_train, df_dummies], axis=1)\n",
    "\n",
    "# # apply the same dummies on the test set\n",
    "# col = 'Color3'\n",
    "# df_dummies = pd.get_dummies(df_test[col])\n",
    "# df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "# df_test = pd.concat([df_test, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: MaturitySize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    6879\n",
      "1    2261\n",
      "3     842\n",
      "4      18\n",
      "Name: MaturitySize, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['MaturitySize'].value_counts())\n",
    "\n",
    "# apply dummies on the training set\n",
    "col = 'MaturitySize'\n",
    "df_dummies = pd.get_dummies(df_train[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_train = pd.concat([df_train, df_dummies], axis=1)\n",
    "\n",
    "# apply the same dummies on the test set\n",
    "col = 'MaturitySize'\n",
    "df_dummies = pd.get_dummies(df_test[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_test = pd.concat([df_test, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: FurLength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5865\n",
      "2    3591\n",
      "3     544\n",
      "Name: FurLength, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['FurLength'].value_counts())\n",
    "\n",
    "# apply dummies on the training set\n",
    "col = 'FurLength'\n",
    "df_dummies = pd.get_dummies(df_train[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_train = pd.concat([df_train, df_dummies], axis=1)\n",
    "\n",
    "# apply the same dummies on the test set\n",
    "col = 'FurLength'\n",
    "df_dummies = pd.get_dummies(df_test[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_test = pd.concat([df_test, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Vaccinated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_train['Vaccinated'].value_counts())\n",
    "\n",
    "# # apply dummies on the training set\n",
    "# col = 'Vaccinated'\n",
    "# df_dummies = pd.get_dummies(df_train[col])\n",
    "# df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "# df_train = pd.concat([df_train, df_dummies], axis=1)\n",
    "\n",
    "# # apply the same dummies on the test set\n",
    "# col = 'Vaccinated'\n",
    "# df_dummies = pd.get_dummies(df_test[col])\n",
    "# df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "# df_test = pd.concat([df_test, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Dewormed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    5625\n",
      "2    3200\n",
      "3    1175\n",
      "Name: Dewormed, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['Dewormed'].value_counts())\n",
    "\n",
    "# apply dummies on the training set\n",
    "col = 'Dewormed'\n",
    "df_dummies = pd.get_dummies(df_train[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_train = pd.concat([df_train, df_dummies], axis=1)\n",
    "\n",
    "# apply the same dummies on the test set\n",
    "col = 'Dewormed'\n",
    "df_dummies = pd.get_dummies(df_test[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_test = pd.concat([df_test, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Sterilized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    6737\n",
      "1    2080\n",
      "3    1183\n",
      "Name: Sterilized, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['Sterilized'].value_counts())\n",
    "\n",
    "# apply dummies on the training set\n",
    "col = 'Sterilized'\n",
    "df_dummies = pd.get_dummies(df_train[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_train = pd.concat([df_train, df_dummies], axis=1)\n",
    "\n",
    "# apply the same dummies on the test set\n",
    "col = 'Sterilized'\n",
    "df_dummies = pd.get_dummies(df_test[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_test = pd.concat([df_test, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply dummies on the training set\n",
    "col = 'Health'\n",
    "df_dummies = pd.get_dummies(df_train[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_train = pd.concat([df_train, df_dummies], axis=1)\n",
    "\n",
    "# apply the same dummies on the test set\n",
    "col = 'Health'\n",
    "df_dummies = pd.get_dummies(df_test[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_test = pd.concat([df_test, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41326    5790\n",
      "41401    2567\n",
      "41327     574\n",
      "41336     342\n",
      "41330     275\n",
      "41332     175\n",
      "41324      96\n",
      "41325      72\n",
      "41335      54\n",
      "41345      16\n",
      "41361      14\n",
      "41367      12\n",
      "41342      11\n",
      "41415       2\n",
      "Name: State, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['State'].value_counts())\n",
    "\n",
    "# apply dummies on the training set\n",
    "col = 'State'\n",
    "df_dummies = pd.get_dummies(df_train[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_train = pd.concat([df_train, df_dummies], axis=1)\n",
    "\n",
    "# apply the same dummies on the test set\n",
    "col = 'State'\n",
    "df_dummies = pd.get_dummies(df_test[col])\n",
    "df_dummies.columns = [str(col)+'_'+str(c) for c in df_dummies.columns]\n",
    "df_test = pd.concat([df_test, df_dummies], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature: RescuerID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fa90fa5b1ee11c86938398b60abc32cb    307\n",
      "aa66486163b6cbc25ea62a34b11c9b91    205\n",
      "c00756f2bdd8fa88fc9f07a8309f7d5d    167\n",
      "b53c34474d9e24574bcec6a3d3306a0d    152\n",
      "ee2747ce26468ec44c7194e7d1d9dad9    113\n",
      "95481e953f8aed9ec3d16fc4509537e8     95\n",
      "a042471e0f43f2cf707104a1a138a7df     70\n",
      "b770bac0ca797cf1433c48a35d30c4cb     70\n",
      "fd970cc91d06d82eebf046340137b272     62\n",
      "438a9bdce8ef4d5948fc40e422d34d0d     57\n",
      "7ed6d84e2e6879245e55447aee39c328     57\n",
      "e62135526c27156b8479420aad166317     52\n",
      "8b6c5cd067ada5f54ca5ffc7f7b5d896     48\n",
      "cccb18b8f8b81862f9a1ebc65d651d22     46\n",
      "530f57b53cb3199e1d5e67733ddc0876     44\n",
      "Name: RescuerID, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train['RescuerID'].value_counts().head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['fa90fa5b1ee11c86938398b60abc32cb'] = np.where(df_train['RescuerID'].str.contains(\"fa90fa5b1ee11c86938398b60abc32cb\")==True, '1', '0')\n",
    "# df_train['fa90fa5b1ee11c86938398b60abc32cb'] = df_train['fa90fa5b1ee11c86938398b60abc32cb'].astype(int)\n",
    "\n",
    "# df_test['fa90fa5b1ee11c86938398b60abc32cb'] = np.where(df_test['RescuerID'].str.contains(\"fa90fa5b1ee11c86938398b60abc32cb\")==True, '1', '0')\n",
    "# df_test['fa90fa5b1ee11c86938398b60abc32cb'] = df_test['fa90fa5b1ee11c86938398b60abc32cb'].astype(int)\n",
    "\n",
    "# df_test['aa66486163b6cbc25ea62a34b11c9b91'] = np.where(df_test['RescuerID'].str.contains(\"aa66486163b6cbc25ea62a34b11c9b91\")==True, '1', '0')\n",
    "# df_test['aa66486163b6cbc25ea62a34b11c9b91'] = df_test['aa66486163b6cbc25ea62a34b11c9b91'].astype(int)\n",
    "\n",
    "# df_train['aa66486163b6cbc25ea62a34b11c9b91'] = np.where(df_train['RescuerID'].str.contains(\"aa66486163b6cbc25ea62a34b11c9b91\")==True, '1', '0')\n",
    "# df_train['aa66486163b6cbc25ea62a34b11c9b91'] = df_train['aa66486163b6cbc25ea62a34b11c9b91'].astype(int)\n",
    "\n",
    "# df_test['c00756f2bdd8fa88fc9f07a8309f7d5d'] = np.where(df_test['RescuerID'].str.contains(\"c00756f2bdd8fa88fc9f07a8309f7d5d\")==True, '1', '0')\n",
    "# df_test['c00756f2bdd8fa88fc9f07a8309f7d5d'] = df_test['c00756f2bdd8fa88fc9f07a8309f7d5d'].astype(int)\n",
    "\n",
    "# df_train['c00756f2bdd8fa88fc9f07a8309f7d5d'] = np.where(df_train['RescuerID'].str.contains(\"c00756f2bdd8fa88fc9f07a8309f7d5d\")==True, '1', '0')\n",
    "# df_train['c00756f2bdd8fa88fc9f07a8309f7d5d'] = df_train['c00756f2bdd8fa88fc9f07a8309f7d5d'].astype(int)\n",
    "\n",
    "# df_test['b53c34474d9e24574bcec6a3d3306a0d'] = np.where(df_test['RescuerID'].str.contains(\"b53c34474d9e24574bcec6a3d3306a0d\")==True, '1', '0')\n",
    "# df_test['b53c34474d9e24574bcec6a3d3306a0d'] = df_test['b53c34474d9e24574bcec6a3d3306a0d'].astype(int)\n",
    "\n",
    "# df_train['b53c34474d9e24574bcec6a3d3306a0d'] = np.where(df_train['RescuerID'].str.contains(\"b53c34474d9e24574bcec6a3d3306a0d\")==True, '1', '0')\n",
    "# df_train['b53c34474d9e24574bcec6a3d3306a0d'] = df_train['b53c34474d9e24574bcec6a3d3306a0d'].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature: Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Start with one review:\n",
    "# text = df_train.Description[0]\n",
    "\n",
    "\n",
    "# text = ' '.join(df_train['Description'])\n",
    "# print (\"There are {} words in the combination of all review.\".format(len(text)))\n",
    "\n",
    "# # Create stopword list:\n",
    "# stopwords = set(STOPWORDS)\n",
    "# stopwords.update([\"drink\", \"now\", \"wine\", \"flavor\", \"flavors\"])\n",
    "\n",
    "\n",
    "# # Create and generate a word cloud image:\n",
    "# wordcloud = WordCloud(stopwords=stopwords, background_color=\"white\").generate(text)\n",
    "\n",
    "# # Display the generated image:\n",
    "# plt.imshow(wordcloud, interpolation='bilinear')\n",
    "# plt.axis(\"off\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['loving'] = np.where(df_train['Description'].str.contains(\"loving\")==True, '1', '0')\n",
    "df_train['loving'] = df_train['loving'].astype(int)\n",
    "\n",
    "df_test['loving'] = np.where(df_test['Description'].str.contains(\"loving\")==True, '1', '0')\n",
    "df_test['loving'] = df_test['loving'].astype(int)\n",
    "\n",
    "df_train['adopt'] = np.where(df_train['Description'].str.contains(\"adopt\")==True, '1', '0')\n",
    "df_train['adopt'] = df_train['adopt'].astype(int)\n",
    "\n",
    "df_test['adopt'] = np.where(df_test['Description'].str.contains(\"adopt\")==True, '1', '0')\n",
    "df_test['adopt'] = df_test['adopt'].astype(int)\n",
    "\n",
    "df_train['adopted'] = np.where(df_train['Description'].str.contains(\"adopted\")==True, '1', '0')\n",
    "df_train['adopted'] = df_train['adopted'].astype(int)\n",
    "\n",
    "df_test['adopted'] = np.where(df_test['Description'].str.contains(\"adopted\")==True, '1', '0')\n",
    "df_test['adopted'] = df_test['adopted'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Type', 'Name', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
      "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', 'Dewormed',\n",
      "       'Sterilized', 'Health', 'Quantity', 'Fee', 'State', 'RescuerID',\n",
      "       'VideoAmt', 'Description', 'PetID', 'PhotoAmt', 'AdoptionSpeed',\n",
      "       'Type_1', 'Type_2', 'Name Status', 'M1', 'M13-M24', 'M168+', 'M2',\n",
      "       'M212-M168', 'M25-M72', 'M3', 'M4', 'M5', 'M6', 'M7-M12', 'M73-M120',\n",
      "       'T1', 'T10', 'T11', 'T12', 'T13', 'T14', 'T15', 'T16', 'T17', 'T18',\n",
      "       'T19', 'T2', 'T20', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'TX',\n",
      "       'Gender_1', 'Gender_2', 'Gender_3', 'MaturitySize_1', 'MaturitySize_2',\n",
      "       'MaturitySize_3', 'MaturitySize_4', 'FurLength_1', 'FurLength_2',\n",
      "       'FurLength_3', 'Dewormed_1', 'Dewormed_2', 'Dewormed_3', 'Sterilized_1',\n",
      "       'Sterilized_2', 'Sterilized_3', 'Health_1', 'Health_2', 'Health_3',\n",
      "       'State_41324', 'State_41325', 'State_41326', 'State_41327',\n",
      "       'State_41330', 'State_41332', 'State_41335', 'State_41336',\n",
      "       'State_41342', 'State_41345', 'State_41361', 'State_41367',\n",
      "       'State_41401', 'State_41415', 'loving', 'adopt', 'adopted'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Train & Test Data for Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = list(df_train)\n",
    "\n",
    "# items to be removed \n",
    "unwanted_feature = {'Type', 'Name', 'Age', 'Breed1', 'Breed2', 'Gender', 'Color1', 'Color2',\n",
    "       'Color3', 'MaturitySize', 'FurLength', 'Vaccinated', '',\n",
    "       'Sterilized', 'Health', 'State', 'RescuerID',\n",
    "       'VideoAmt', 'Description', 'PetID', 'AdoptionSpeed', 'Color'}\n",
    "\n",
    "\n",
    "list1 = [ele for ele in feature if ele not in unwanted_feature]\n",
    "\n",
    "# list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the columns\n",
    "X_columns = list1\n",
    "y_column = ['AdoptionSpeed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (6600, 76)\n",
      "y_train (6600, 1)\n",
      "X_test (3400, 76)\n",
      "y_test (3400, 1)\n"
     ]
    }
   ],
   "source": [
    "# split the data using sklearn\n",
    "\n",
    "threshold = 0.66\n",
    "X = df_train[X_columns]\n",
    "y = df_train[y_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1.0-threshold, shuffle=True)\n",
    "\n",
    "print('X_train', X_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(model_name, model, X_train, y_train):\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "    \n",
    "def model_prediction(model, X_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "def model_evaluation(model_name, y_test, y_pred):\n",
    "    kappa = cohen_kappa_score(y_test, y_pred, weights ='quadratic')\n",
    "    print(model_name)\n",
    "    print('kappa', round(kappa, 4))\n",
    "#     plt.scatter(y_test, y_pred, alpha=0.3)\n",
    "#     plt.plot(range(0,5000000, 100), range(0,5000000, 100), '--r', alpha=0.3, label='Line1')\n",
    "#     plt.title(model_name)\n",
    "#     plt.xlabel('True Value')\n",
    "#     plt.ylabel('Predict Value')\n",
    "#     plt.xlim([0, 5000000])\n",
    "#     plt.ylim([0, 5000000])\n",
    "#     plt.show()\n",
    "    print('')\n",
    "\n",
    "def run_experiment(model_name, model, X_train, y_train, X_test):\n",
    "    train_model = model_training(model_name, model, X_train, y_train)\n",
    "    predictions = model_prediction(train_model, X_test)\n",
    "    model_evaluation(model_name, y_test, predictions)\n",
    "    \n",
    "# run_experiment('KNN', KNeighborsClassifier(), X_train, y_train, X_test)\n",
    "# run_experiment('SVC Kernel', SVC(kernel=\"linear\", C=0.025), X_train, y_train, X_test)\n",
    "# run_experiment('SVC Gamma', SVC(kernel=\"linear\", C=0.025), X_train, y_train, X_test)\n",
    "\n",
    "# run_experiment('DecisionTree', DecisionTreeClassifier(), X_train, y_train, X_test)\n",
    "# run_experiment('RandomForest 10', RandomForestClassifier(10), X_train, y_train, X_test)\n",
    "# run_experiment('RandomForest 100', RandomForestClassifier(100), X_train, y_train, X_test)\n",
    "# run_experiment('GradientBoosting', GradientBoostingClassifier(), X_train, y_train, X_test)\n",
    "# run_experiment('QuadraticDiscriminantAnalysis', QuadraticDiscriminantAnalysis(), X_train, y_train, X_test)\n",
    "# run_experiment('GaussianProcess', GaussianProcessClassifier(), X_train, y_train, X_test)\n",
    "# run_experiment('GaussianNB', GaussianNB(), X_train, y_train, X_test)\n",
    "\n",
    "# run_experiment('Gradient Boosting', GradientBoostingRegressor(), X_train, y_train, X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a GradientBoosting Classifier\n",
    "model = GradientBoostingClassifier()\n",
    "model.fit(X_train, y_train.values.ravel())\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kappa 0.3214\n",
      "[[  1  28  27   8  28]\n",
      " [  3 177 300  58 162]\n",
      " [  3 142 381 118 253]\n",
      " [  0  98 266 128 257]\n",
      " [  2  69 186  64 641]]\n"
     ]
    }
   ],
   "source": [
    "kappa = cohen_kappa_score(y_test, y_pred, weights ='quadratic')\n",
    "print('kappa', round(kappa, 4))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa for each fold: [0.3626, 0.3257, 0.3148]\n",
      "AVG(kappa) 0.3344\n",
      "STD(kappa) 0.0205\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "results = []\n",
    "kf = KFold(n_splits=k)\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.values[train_index], X.values[test_index]\n",
    "    y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "    model.fit(X_train, y_train.ravel())\n",
    "    y_pred = model.predict(X_test)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred, weights ='quadratic')\n",
    "    results.append(round(kappa, 4))\n",
    "\n",
    "print('Kappa for each fold:', results)\n",
    "print('AVG(kappa)', round(np.mean(results), 4))\n",
    "print('STD(kappa)', round(np.std(results), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare your submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>f42161740</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0118db3a8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e5164d828</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5335bfb38</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ff2cf88a0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1d13441b9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7d835cf7c</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>577d15fea</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>91736f444</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>db194aec8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10516f3c6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>c3106dcd5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>fc3fbbb99</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>42dd3f3ff</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>da3be5cb2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4e9a13862</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2fbf2cb7c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>f45457bdc</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>aad08c47b</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>181d40c5e</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1a3c44785</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6786609aa</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1c67c5f4c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>bf6a56d33</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>06fda20a2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>b940cf8b8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>239c4b696</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>b67a29908</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>72f092b4b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7d1d7a4f6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963</th>\n",
       "      <td>ed0185e39</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4964</th>\n",
       "      <td>bf90589d1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4965</th>\n",
       "      <td>0f796d3f9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4966</th>\n",
       "      <td>6d53b2d19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4967</th>\n",
       "      <td>7bc54baef</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4968</th>\n",
       "      <td>87615b2c6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4969</th>\n",
       "      <td>6f07e7abf</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>3bf6cdab0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>00ac364a4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>578b82f50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>f24991ef7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>2e9a64836</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>3dab3050c</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>4f6029457</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>b23e29c89</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>0c46298f8</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>2f6cde44b</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>2f3677597</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>256f40704</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>653f94080</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>878e36da4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>46cf6356e</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>ef50eab33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>a40116bf1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>7ed14130d</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>3b2b69d20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>360215e23</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>0c612e8df</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>9b1241ef0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>ffe7f0b70</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4993 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          PetID  AdoptionSpeed\n",
       "0     f42161740              2\n",
       "1     0118db3a8              4\n",
       "2     e5164d828              2\n",
       "3     5335bfb38              4\n",
       "4     ff2cf88a0              4\n",
       "5     1d13441b9              2\n",
       "6     7d835cf7c              3\n",
       "7     577d15fea              2\n",
       "8     91736f444              4\n",
       "9     db194aec8              2\n",
       "10    10516f3c6              2\n",
       "11    c3106dcd5              3\n",
       "12    fc3fbbb99              4\n",
       "13    42dd3f3ff              2\n",
       "14    da3be5cb2              4\n",
       "15    4e9a13862              2\n",
       "16    2fbf2cb7c              2\n",
       "17    f45457bdc              4\n",
       "18    aad08c47b              4\n",
       "19    181d40c5e              4\n",
       "20    1a3c44785              4\n",
       "21    6786609aa              4\n",
       "22    1c67c5f4c              1\n",
       "23    bf6a56d33              4\n",
       "24    06fda20a2              4\n",
       "25    b940cf8b8              2\n",
       "26    239c4b696              2\n",
       "27    b67a29908              2\n",
       "28    72f092b4b              1\n",
       "29    7d1d7a4f6              2\n",
       "...         ...            ...\n",
       "4963  ed0185e39              4\n",
       "4964  bf90589d1              4\n",
       "4965  0f796d3f9              1\n",
       "4966  6d53b2d19              1\n",
       "4967  7bc54baef              4\n",
       "4968  87615b2c6              4\n",
       "4969  6f07e7abf              2\n",
       "4970  3bf6cdab0              3\n",
       "4971  00ac364a4              4\n",
       "4972  578b82f50              1\n",
       "4973  f24991ef7              3\n",
       "4974  2e9a64836              2\n",
       "4975  3dab3050c              4\n",
       "4976  4f6029457              1\n",
       "4977  b23e29c89              3\n",
       "4978  0c46298f8              4\n",
       "4979  2f6cde44b              4\n",
       "4980  2f3677597              4\n",
       "4981  256f40704              4\n",
       "4982  653f94080              3\n",
       "4983  878e36da4              4\n",
       "4984  46cf6356e              2\n",
       "4985  ef50eab33              1\n",
       "4986  a40116bf1              4\n",
       "4987  7ed14130d              3\n",
       "4988  3b2b69d20              3\n",
       "4989  360215e23              2\n",
       "4990  0c612e8df              4\n",
       "4991  9b1241ef0              4\n",
       "4992  ffe7f0b70              4\n",
       "\n",
       "[4993 rows x 2 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prediction = df_test[X_columns]\n",
    "df_test['AdoptionSpeed'] = model.predict(df_prediction)\n",
    "df_test[['PetID', 'AdoptionSpeed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['PetID', 'AdoptionSpeed']].to_csv('Submission/submission_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
